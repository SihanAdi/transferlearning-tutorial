# 迁移学习的问题形式化

迁移学习的问题形式化是进行一切研究的前提。在迁移学习中，有两个基本的概念：**领域(Domain)** 和 **任务(Task)**。它们是最基础的概念。定义如下：

## 领域 Domain

**领域(Domain):** 是进行学习的主体。领域主要由两部分构成：**数据** 和生成这些数据的 **概率分布**。通常我们用花体$$\mathcal{D}$$ 来表示一个 domain，用大写斜体 $$P$$ 来表示一个概率分布。

特别地，因为涉及到迁移，所以对应于两个基本的领域：**源领域(Source Domain)** 和 **目标领域(Target Domain)**。这两个概念很好理解。源领域就是有知识、有大量数据标注的领域，是我们要迁移的对象；目标领域就是我们最终要赋予知识、赋予标注的对象。知识从源领域传递到目标领域，就完成了迁移。

领域上的数据，我们通常用小写粗体$$\mathbf{x}$$ 来表示，它也是向量的表示形式。例如，$$\mathbf{x}_i$$ 就表示第 $$i$$ 个样本或特征。用大写的黑体 $$\mathbf{X}$$ 表示一个领域的数据，这是一种矩阵形式。我们用大写花体 $$\mathcal{X}$$ 来表示数据的特征空间。

通常我们用小写下标 $$s$$ 和 $$t$$ 来分别指代两个领域。结合领域的表示方式，则：$$\mathcal{D}_s$$ 表示源领域，$$\mathcal{D}_t$$ 表示目标领域。

值得注意的是，概率分布 $$P$$ 通常只是一个逻辑上的概念，即我们认为不同领域有不同的概率分布，却一般不给出（也难以给出）$$P$$ 的具体形式。

## 任务 Task

**任务(Task):** 是学习的目标。任务主要由两部分组成：**标签** 和 **标签对应的函数**。通常我们用花体 $$\mathcal{Y}$$ 来表示一个标签空间，用 $$f(\cdot)$$ 来表示一个学习函数。

相应地，源领域和目标领域的类别空间就可以分别表示为 $$\mathcal{Y}_s$$ 和 $$\mathcal{Y}_t$$。我们用小写 $$y_s$$ 和 $$y_t$$ 分别表示源领域和目标领域的实际类别。

## 迁移学习

有了上面领域和任务的定义，我们就可以对迁移学习进行形式化。

**迁移学习(Transfer Learning):** 给定一个有标记的源域$$\mathcal{D}_s=\{\mathbf{x}_{i},y_{i}\}^n_{i=1}$$ 和一个无标记的目标域$$\mathcal{D}_t=\{\mathbf{x}_{j}\}^{n+m}_{j=n+1}$$。这两个领域的数据分布$$P(\mathbf{x}_s)$$ 和 $$P(\mathbf{x}_t)$$ 不同，即 $$P(\mathbf{x}_s) \ne P(\mathbf{x}_t)$$。迁移学习的目的就是要借助 $$\mathcal{D}_s$$ 的知识，来学习目标域 $$\mathcal{D}_t$$ 的知识(标签)。

更进一步，结合我们前面说过的迁移学习研究领域，迁移学习的定义需要进行如下的考虑：

(1) 特征空间的异同，即 $$\mathcal{X}_s$$ 和 $$\mathcal{X}_t$$ 是否相等。

(2) 类别空间的异同：即 $$\mathcal{Y}_s$$ 和 $$\mathcal{Y}_t$$ 是否相等。

(3) 条件概率分布的异同：即 $$Q_s(y_s|\mathbf{x}_s)$$ 和 $$Q_t(y_t|\mathbf{x}_t)$$ 是否相等。

结合上述形式化，我们给出 **领域自适应(Domain Adaptation):** 给定一个有标记的源域$$\mathcal{D}_s=\{\mathbf{x}_{i},y_{i}\}^n_{i=1}$$ 和一个无标记的目标域$$\mathcal{D_t}=\{\mathbf{x}_{j}\}^{n+m}_{j=n+1}$$，假定它们的特征空间相同，即$$\mathcal{X}_s = \mathcal{X}_t$$，并且它们的类别空间也相同，即$$\mathcal{Y}_s = \mathcal{Y}_t$$以及条件概率分布也相同，即$$Q_s(y_s|\mathbf{x}_s) = Q_t(y_t|\mathbf{x}_t)$$。但是这两个域的边缘分布不同，即$$P_s(\mathbf{x}_s) \ne P_t(\mathbf{x}_t)$$。迁移学习的目标就是，利用有标记的数据$$\mathcal{D}_s$$去学习一个分类器$$f:\mathbf{x}_t \mapsto y_t$$来预测目标域$$\mathcal{D}_t$$的标签$$y_t \in \mathcal{Y}_t$$。

在实际的研究和应用中，读者可以针对自己的不同任务，结合上述表述，灵活地给出相关的形式化定义。

**符号小结**

我们已经基本介绍了迁移学习中常用的符号。下表是一个符号表：

|                                   符号                                  |               含义              |
|:-----------------------------------------------------------------------:|:-------------------------------:|
|                            下标$$s$$ / $$t$$                            |        指示源域 / 目标域        |
|                  $$\mathcal{D}_s$$ / $$\mathcal{D}_t$$                  |      源域数据 / 目标域数据      |
|            $$\mathbf{x}$$ /  $$\mathbf{X}$$ / $$\mathcal{X}$$           |      向量 / 矩阵 / 特征空间     |
|                     $$\mathbf{y}$$ / $$\mathcal{Y}$$                    |       类别向量 / 类别空间       |
|              $$(n,m)$$ [或 $$(n_1,n_2)$$ 或 $$(n_s,n_t)$$]              |    (源域样本数,目标域样本数)    |
|                $$P(\mathbf{x}_s)$$ / $$P(\mathbf{x}_t)$$                | 源域数据 / 目标域数据的边缘分布 |
| $$Q(\mathbf{y}_s$$ , $$\mathbf{x}_s)$$ / $$Q(\mathbf{y}_t$$ , $$\mathbf{x}_t)$$ | 源域数据 / 目标域数据的条件分布 |
|                               $$f(\cdot)$$                              |         要学习的目标函数        |
